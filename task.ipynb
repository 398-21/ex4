{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VOSK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Ex4_audio_files/EN/checkin.wav (EN)...\n",
      "Preprocessing Ex4_audio_files/EN/checkin.wav for language en...\n",
      "Loading Ex4_audio_files/EN/checkin.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav for language en...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Final preprocessed audio saved to preprocessed_checkin.wav\n",
      "Processing audio file: preprocessed_checkin.wav\n",
      "Reference: Where is the check-in desk?\n",
      "Recognized: where is the check in desk\n",
      "WER: 0.00%\n",
      "\n",
      "Processing Ex4_audio_files/EN/parents.wav (EN)...\n",
      "Preprocessing Ex4_audio_files/EN/parents.wav for language en...\n",
      "Loading Ex4_audio_files/EN/parents.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav for language en...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Final preprocessed audio saved to preprocessed_parents.wav\n",
      "Processing audio file: preprocessed_parents.wav\n",
      "Reference: I have lost my parents.\n",
      "Recognized: i had lost my parents\n",
      "WER: 20.00%\n",
      "\n",
      "Processing Ex4_audio_files/EN/suitcase.wav (EN)...\n",
      "Preprocessing Ex4_audio_files/EN/suitcase.wav for language en...\n",
      "Loading Ex4_audio_files/EN/suitcase.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav for language en...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Final preprocessed audio saved to preprocessed_suitcase.wav\n",
      "Processing audio file: preprocessed_suitcase.wav\n",
      "Reference: Please, I have lost my suitcase.\n",
      "Recognized: please i've lost my suitcase\n",
      "WER: 21.67%\n",
      "\n",
      "Processing Ex4_audio_files/EN/what_time.wav (EN)...\n",
      "Preprocessing Ex4_audio_files/EN/what_time.wav for language en...\n",
      "Loading Ex4_audio_files/EN/what_time.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav for language en...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Final preprocessed audio saved to preprocessed_what_time.wav\n",
      "Processing audio file: preprocessed_what_time.wav\n",
      "Reference: What time is my plane?\n",
      "Recognized: what time is my plane\n",
      "WER: 0.00%\n",
      "\n",
      "Processing Ex4_audio_files/EN/where.wav (EN)...\n",
      "Preprocessing Ex4_audio_files/EN/where.wav for language en...\n",
      "Loading Ex4_audio_files/EN/where.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav for language en...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Final preprocessed audio saved to preprocessed_where.wav\n",
      "Processing audio file: preprocessed_where.wav\n",
      "Reference: Where are the restaurants and shops?\n",
      "Recognized: where are the restaurants and shops\n",
      "WER: 0.00%\n",
      "\n",
      "Processing Ex4_audio_files/IT/checkin_it.wav (IT)...\n",
      "Preprocessing Ex4_audio_files/IT/checkin_it.wav for language it...\n",
      "Loading Ex4_audio_files/IT/checkin_it.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav for language it...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Final preprocessed audio saved to preprocessed_checkin_it.wav\n",
      "Processing audio file: preprocessed_checkin_it.wav\n",
      "Reference: Dove e' il bancone?\n",
      "Recognized: dove il bancone\n",
      "WER: 7.50%\n",
      "\n",
      "Processing Ex4_audio_files/IT/parents_it.wav (IT)...\n",
      "Preprocessing Ex4_audio_files/IT/parents_it.wav for language it...\n",
      "Loading Ex4_audio_files/IT/parents_it.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav for language it...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Final preprocessed audio saved to preprocessed_parents_it.wav\n",
      "Processing audio file: preprocessed_parents_it.wav\n",
      "Reference: Ho perso i miei genitori.\n",
      "Recognized: ho perso i miei genitori\n",
      "WER: 0.00%\n",
      "\n",
      "Processing Ex4_audio_files/IT/suitcase_it.wav (IT)...\n",
      "Preprocessing Ex4_audio_files/IT/suitcase_it.wav for language it...\n",
      "Loading Ex4_audio_files/IT/suitcase_it.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav for language it...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Final preprocessed audio saved to preprocessed_suitcase_it.wav\n",
      "Processing audio file: preprocessed_suitcase_it.wav\n",
      "Reference: Per favore, ho perso la mia valigia.\n",
      "Recognized: per favore ho perso la mia valigia\n",
      "WER: 0.00%\n",
      "\n",
      "Processing Ex4_audio_files/IT/what_time_it.wav (IT)...\n",
      "Preprocessing Ex4_audio_files/IT/what_time_it.wav for language it...\n",
      "Loading Ex4_audio_files/IT/what_time_it.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav for language it...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Final preprocessed audio saved to preprocessed_what_time_it.wav\n",
      "Processing audio file: preprocessed_what_time_it.wav\n",
      "Reference: A che ora e' il mio aereo?\n",
      "Recognized: a che ora è il mio aereo\n",
      "WER: 0.00%\n",
      "\n",
      "Processing Ex4_audio_files/IT/where_it.wav (IT)...\n",
      "Preprocessing Ex4_audio_files/IT/where_it.wav for language it...\n",
      "Loading Ex4_audio_files/IT/where_it.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav for language it...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Final preprocessed audio saved to preprocessed_where_it.wav\n",
      "Processing audio file: preprocessed_where_it.wav\n",
      "Reference: Dove sono i ristoranti e i negozi?\n",
      "Recognized: dove sono i ristoranti e negozi\n",
      "WER: 4.29%\n",
      "\n",
      "Processing Ex4_audio_files/ES/checkin_es.wav (ES)...\n",
      "Preprocessing Ex4_audio_files/ES/checkin_es.wav for language es...\n",
      "Loading Ex4_audio_files/ES/checkin_es.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav for language es...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Final preprocessed audio saved to preprocessed_checkin_es.wav\n",
      "Processing audio file: preprocessed_checkin_es.wav\n",
      "Reference: ¿Dónde están los mostradores?\n",
      "Recognized: dónde están los mostradores\n",
      "WER: 0.00%\n",
      "\n",
      "Processing Ex4_audio_files/ES/parents_es.wav (ES)...\n",
      "Preprocessing Ex4_audio_files/ES/parents_es.wav for language es...\n",
      "Loading Ex4_audio_files/ES/parents_es.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav for language es...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Final preprocessed audio saved to preprocessed_parents_es.wav\n",
      "Processing audio file: preprocessed_parents_es.wav\n",
      "Reference: He perdido a mis padres.\n",
      "Recognized: he perdido a mis padres\n",
      "WER: 0.00%\n",
      "\n",
      "Processing Ex4_audio_files/ES/suitcase_es.wav (ES)...\n",
      "Preprocessing Ex4_audio_files/ES/suitcase_es.wav for language es...\n",
      "Loading Ex4_audio_files/ES/suitcase_es.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav for language es...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Final preprocessed audio saved to preprocessed_suitcase_es.wav\n",
      "Processing audio file: preprocessed_suitcase_es.wav\n",
      "Reference: Por favor, he perdido mi maleta.\n",
      "Recognized: por favor he perdido mi maleta\n",
      "WER: 0.00%\n",
      "\n",
      "Processing Ex4_audio_files/ES/what_time_es.wav (ES)...\n",
      "Preprocessing Ex4_audio_files/ES/what_time_es.wav for language es...\n",
      "Loading Ex4_audio_files/ES/what_time_es.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav for language es...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Final preprocessed audio saved to preprocessed_what_time_es.wav\n",
      "Processing audio file: preprocessed_what_time_es.wav\n",
      "Reference: ¿A qué hora es mi avión?\n",
      "Recognized: qué hora es mi helio\n",
      "WER: 21.67%\n",
      "\n",
      "Processing Ex4_audio_files/ES/where_es.wav (ES)...\n",
      "Preprocessing Ex4_audio_files/ES/where_es.wav for language es...\n",
      "Loading Ex4_audio_files/ES/where_es.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav for language es...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Final preprocessed audio saved to preprocessed_where_es.wav\n",
      "Processing audio file: preprocessed_where_es.wav\n",
      "Reference: ¿Dónde están los restaurantes y las tiendas?\n",
      "Recognized: dónde están los restaurantes en las tiendas\n",
      "WER: 4.29%\n",
      "\n",
      "Processing Ex4_audio_files/EN/where-is.mp3 (EN)...\n",
      "Preprocessing Ex4_audio_files/EN/where-is.mp3 for language en...\n",
      "Loading Ex4_audio_files/EN/where-is.mp3 for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav for language en...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Final preprocessed audio saved to preprocessed_where-is.mp3\n",
      "Processing audio file: preprocessed_where-is.mp3\n",
      "Reference: Where is my keyboard?\n",
      "Recognized: where is my keyboard\n",
      "WER: 0.00%\n",
      "\n",
      "Processing Ex4_audio_files/EN/blanket.mp3 (EN)...\n",
      "Preprocessing Ex4_audio_files/EN/blanket.mp3 for language en...\n",
      "Loading Ex4_audio_files/EN/blanket.mp3 for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav for language en...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Final preprocessed audio saved to preprocessed_blanket.mp3\n",
      "Processing audio file: preprocessed_blanket.mp3\n",
      "Reference: Can I have a blanket please\n",
      "Recognized: can i have a blanket police\n",
      "WER: 16.67%\n",
      "\n",
      "--- Evaluation Results ---\n",
      "Ex4_audio_files/EN/checkin.wav EN         0.00      \n",
      "Ex4_audio_files/EN/parents.wav EN         20.00     \n",
      "Ex4_audio_files/EN/suitcase.wav EN         21.67     \n",
      "Ex4_audio_files/EN/what_time.wav EN         0.00      \n",
      "Ex4_audio_files/EN/where.wav   EN         0.00      \n",
      "Ex4_audio_files/IT/checkin_it.wav IT         7.50      \n",
      "Ex4_audio_files/IT/parents_it.wav IT         0.00      \n",
      "Ex4_audio_files/IT/suitcase_it.wav IT         0.00      \n",
      "Ex4_audio_files/IT/what_time_it.wav IT         0.00      \n",
      "Ex4_audio_files/IT/where_it.wav IT         4.29      \n",
      "Ex4_audio_files/ES/checkin_es.wav ES         0.00      \n",
      "Ex4_audio_files/ES/parents_es.wav ES         0.00      \n",
      "Ex4_audio_files/ES/suitcase_es.wav ES         0.00      \n",
      "Ex4_audio_files/ES/what_time_es.wav ES         21.67     \n",
      "Ex4_audio_files/ES/where_es.wav ES         4.29      \n",
      "Ex4_audio_files/EN/where-is.mp3 EN         0.00      \n",
      "Ex4_audio_files/EN/blanket.mp3 EN         16.67     \n",
      "\n",
      "--- Average WER by Language ---\n",
      "EN: 8.33%\n",
      "IT: 2.36%\n",
      "ES: 5.19%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wave\n",
    "import json\n",
    "from vosk import Model, KaldiRecognizer\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import noisereduce as nr\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "# Normalize text\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"-\", \" \", text)\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    text = unicodedata.normalize('NFD', text)\n",
    "    text = \"\".join([c for c in text if unicodedata.category(c) != 'Mn'])\n",
    "    return text\n",
    "\n",
    "# Adaptive noise reduction\n",
    "def adaptive_noise_reduction(input_file, output_file):\n",
    "    print(f\"Loading {input_file} for adaptive noise reduction...\")\n",
    "    try:\n",
    "        y, sr = librosa.load(input_file, sr=None)\n",
    "        if len(y) == 0:\n",
    "            print(\"Warning: Input audio is empty. Copying as is.\")\n",
    "            sf.write(output_file, y, sr)\n",
    "            return input_file\n",
    "\n",
    "        noise_profile = y[:int(sr * 0.8)]  # Use first 0.5 seconds for noise profile\n",
    "        y_denoised = nr.reduce_noise(y=y, y_noise=noise_profile, sr=sr, prop_decrease=0.7)\n",
    "        sf.write(output_file, y_denoised, sr)\n",
    "        print(f\"Noise-reduced audio saved to {output_file}\")\n",
    "        return output_file\n",
    "    except Exception as e:\n",
    "        print(f\"Error in noise reduction: {e}\")\n",
    "        return input_file\n",
    "\n",
    "# Equalization with language-specific parameters\n",
    "def apply_equalization(input_file, output_file, lang):\n",
    "    print(f\"Applying equalization to {input_file} for language {lang}...\")\n",
    "    try:\n",
    "        audio = AudioSegment.from_wav(input_file)\n",
    "\n",
    "        # Language-specific high-pass and low-pass filter values\n",
    "        if lang == \"en\":\n",
    "            high_pass = 200\n",
    "            low_pass = 2000\n",
    "        elif lang == \"es\":\n",
    "            high_pass = 250\n",
    "            low_pass = 3500\n",
    "        elif lang == \"it\":\n",
    "            high_pass = 100\n",
    "            low_pass = 3000\n",
    "        else:\n",
    "            high_pass = 200\n",
    "            low_pass = 5000  # Default values\n",
    "\n",
    "        boosted_audio = audio.high_pass_filter(high_pass).low_pass_filter(low_pass)\n",
    "        boosted_audio.export(output_file, format=\"wav\")\n",
    "        print(f\"Equalized audio saved to {output_file}\")\n",
    "        return output_file\n",
    "    except Exception as e:\n",
    "        print(f\"Error in equalization: {e}\")\n",
    "        return input_file\n",
    "\n",
    "# Preprocessing pipeline\n",
    "def preprocess_audio(input_file, output_file, lang):\n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"Error: File {input_file} does not exist.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Preprocessing {input_file} for language {lang}...\")\n",
    "    try:\n",
    "        noise_reduced_file = \"temp_noise_reduced.wav\"\n",
    "        noise_reduced = adaptive_noise_reduction(input_file, noise_reduced_file)\n",
    "\n",
    "        equalized_file = \"temp_equalized.wav\"\n",
    "        equalized = apply_equalization(noise_reduced, equalized_file, lang)\n",
    "\n",
    "        final_audio = AudioSegment.from_wav(equalized).set_channels(1).set_frame_rate(16000)\n",
    "        final_audio.export(output_file, format=\"wav\")\n",
    "        print(f\"Final preprocessed audio saved to {output_file}\")\n",
    "        return output_file\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing audio: {e}\")\n",
    "        return None\n",
    "\n",
    "# Transcribe using Vosk\n",
    "def transcribe_vosk(audio_file, model_path):\n",
    "    print(f\"Processing audio file: {audio_file}\")\n",
    "    try:\n",
    "        model = Model(model_path)\n",
    "        rec = KaldiRecognizer(model, 16000)\n",
    "        rec.SetWords(True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Vosk model: {e}\")\n",
    "        return \"Error: Failed to load Vosk model.\"\n",
    "\n",
    "    try:\n",
    "        with wave.open(audio_file, \"rb\") as wf:\n",
    "            while True:\n",
    "                data = wf.readframes(4000)\n",
    "                if len(data) == 0:\n",
    "                    break\n",
    "                rec.AcceptWaveform(data)\n",
    "        result = json.loads(rec.FinalResult())\n",
    "        return result.get(\"text\", \"\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing audio with Vosk: {e}\")\n",
    "        return \"Error: Failed to process audio.\"\n",
    "\n",
    "# Calculate WER\n",
    "def calculate_wer_custom(reference, hypothesis):\n",
    "    \"\"\"\n",
    "    Calculates Word Error Rate (WER) with normalization applied,\n",
    "    ensuring minor impact for single-letter words and better handling of deletions and insertions.\n",
    "    \"\"\"\n",
    "    # Normalize both reference and hypothesis\n",
    "    reference = normalize_text(reference)\n",
    "    hypothesis = normalize_text(hypothesis)\n",
    "\n",
    "    # Tokenize into words\n",
    "    reference_words = reference.split()\n",
    "    hypothesis_words = hypothesis.split()\n",
    "\n",
    "    # Initialize substitution, deletion, and insertion counters\n",
    "    substitutions, deletions, insertions = 0, 0, 0\n",
    "\n",
    "    # Align reference and hypothesis words using dynamic programming (Levenshtein distance)\n",
    "    ref_len, hyp_len = len(reference_words), len(hypothesis_words)\n",
    "    dp = [[0] * (hyp_len + 1) for _ in range(ref_len + 1)]\n",
    "\n",
    "    # Fill the DP table\n",
    "    for i in range(ref_len + 1):\n",
    "        for j in range(hyp_len + 1):\n",
    "            if i == 0:\n",
    "                dp[i][j] = j  # All insertions\n",
    "            elif j == 0:\n",
    "                dp[i][j] = i  # All deletions\n",
    "            elif reference_words[i - 1] == hypothesis_words[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]  # No penalty for a match\n",
    "            else:\n",
    "                # Assign weights: 0.3 for single-letter mismatches, 1 for others\n",
    "                subst_cost = (\n",
    "                    0.3\n",
    "                    if len(reference_words[i - 1]) == 1 or len(hypothesis_words[j - 1]) == 1\n",
    "                    else 1\n",
    "                )\n",
    "                dp[i][j] = min(\n",
    "                    dp[i - 1][j - 1] + subst_cost,  # Substitution\n",
    "                    dp[i - 1][j] + 1,  # Deletion\n",
    "                    dp[i][j - 1] + 1,  # Insertion\n",
    "                )\n",
    "\n",
    "    # Backtrack to count substitutions, deletions, and insertions\n",
    "    i, j = ref_len, hyp_len\n",
    "    while i > 0 and j > 0:\n",
    "        if reference_words[i - 1] == hypothesis_words[j - 1]:\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif dp[i][j] == dp[i - 1][j - 1] + (\n",
    "            0.3 if len(reference_words[i - 1]) == 1 or len(hypothesis_words[j - 1]) == 1 else 1\n",
    "        ):\n",
    "            substitutions += 0.3 if len(reference_words[i - 1]) == 1 or len(hypothesis_words[j - 1]) == 1 else 1\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif dp[i][j] == dp[i - 1][j] + 1:\n",
    "            deletions += 0.3 if len(reference_words[i - 1]) == 1 else 1\n",
    "            i -= 1\n",
    "        else:\n",
    "            insertions += 0.3 if len(hypothesis_words[j - 1]) == 1 else 1\n",
    "            j -= 1\n",
    "\n",
    "    # Handle remaining deletions and insertions\n",
    "    while i > 0:\n",
    "        deletions += 0.3 if len(reference_words[i - 1]) == 1 else 1\n",
    "        i -= 1\n",
    "    while j > 0:\n",
    "        insertions += 0.3 if len(hypothesis_words[j - 1]) == 1 else 1\n",
    "        j -= 1\n",
    "\n",
    "    # Calculate WER\n",
    "    reference_length = len(reference_words)\n",
    "\n",
    "    # Handle edge case for empty reference\n",
    "    if reference_length == 0:\n",
    "        return 100.0 if substitutions + deletions + insertions > 0 else 0.0\n",
    "\n",
    "    wer = ((substitutions + deletions + insertions) / reference_length) * 100\n",
    "    return round(wer, 2)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_asr():\n",
    "    audio_files = [\n",
    "        {\"file\": \"Ex4_audio_files/EN/checkin.wav\", \"lang\": \"en\", \"truth\": \"Where is the check-in desk?\"},\n",
    "        {\"file\": \"Ex4_audio_files/EN/parents.wav\", \"lang\": \"en\", \"truth\": \"I have lost my parents.\"},\n",
    "        {\"file\": \"Ex4_audio_files/EN/suitcase.wav\", \"lang\": \"en\", \"truth\": \"Please, I have lost my suitcase.\"},\n",
    "        {\"file\": \"Ex4_audio_files/EN/what_time.wav\", \"lang\": \"en\", \"truth\": \"What time is my plane?\"},\n",
    "        {\"file\": \"Ex4_audio_files/EN/where.wav\", \"lang\": \"en\", \"truth\": \"Where are the restaurants and shops?\"},\n",
    "        {\"file\": \"Ex4_audio_files/IT/checkin_it.wav\", \"lang\": \"it\", \"truth\": \"Dove e' il bancone?\"},\n",
    "        {\"file\": \"Ex4_audio_files/IT/parents_it.wav\", \"lang\": \"it\", \"truth\": \"Ho perso i miei genitori.\"},\n",
    "        {\"file\": \"Ex4_audio_files/IT/suitcase_it.wav\", \"lang\": \"it\", \"truth\": \"Per favore, ho perso la mia valigia.\"},\n",
    "        {\"file\": \"Ex4_audio_files/IT/what_time_it.wav\", \"lang\": \"it\", \"truth\": \"A che ora e' il mio aereo?\"},\n",
    "        {\"file\": \"Ex4_audio_files/IT/where_it.wav\", \"lang\": \"it\", \"truth\": \"Dove sono i ristoranti e i negozi?\"},\n",
    "        {\"file\": \"Ex4_audio_files/ES/checkin_es.wav\", \"lang\": \"es\", \"truth\": \"¿Dónde están los mostradores?\"},\n",
    "        {\"file\": \"Ex4_audio_files/ES/parents_es.wav\", \"lang\": \"es\", \"truth\": \"He perdido a mis padres.\"},\n",
    "        {\"file\": \"Ex4_audio_files/ES/suitcase_es.wav\", \"lang\": \"es\", \"truth\": \"Por favor, he perdido mi maleta.\"},\n",
    "        {\"file\": \"Ex4_audio_files/ES/what_time_es.wav\", \"lang\": \"es\", \"truth\": \"¿A qué hora es mi avión?\"},\n",
    "        {\"file\": \"Ex4_audio_files/ES/where_es.wav\", \"lang\": \"es\", \"truth\": \"¿Dónde están los restaurantes y las tiendas?\"},\n",
    "        {\"file\": \"Ex4_audio_files/EN/where-is.mp3\", \"lang\": \"en\", \"truth\": \"Where is my keyboard?\"},\n",
    "        {\"file\": \"Ex4_audio_files/EN/blanket.mp3\", \"lang\": \"en\", \"truth\": \"Can I have a blanket please\"},\n",
    "    ]\n",
    "\n",
    "    model_paths = {\n",
    "        \"en\": \"vosk/vosk-model-small-en-us-0.15\",\n",
    "        \"it\": \"vosk/vosk-model-small-it-0.22\",\n",
    "        \"es\": \"vosk/vosk-model-small-es-0.42\"\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    language_wer = {\"EN\": [], \"IT\": [], \"ES\": []}\n",
    "\n",
    "    for item in audio_files:\n",
    "        file = item[\"file\"]\n",
    "        lang = item[\"lang\"]\n",
    "        truth = item[\"truth\"]\n",
    "\n",
    "        print(f\"\\nProcessing {file} ({lang.upper()})...\")\n",
    "        preprocessed_file = f\"preprocessed_{os.path.basename(file)}\"\n",
    "        recognized_text = \"\"\n",
    "\n",
    "        try:\n",
    "            preprocess_audio(file, preprocessed_file, lang)\n",
    "            recognized_text = transcribe_vosk(preprocessed_file, model_paths[lang])\n",
    "        except Exception as e:\n",
    "            recognized_text = f\"Error: {e}\"\n",
    "\n",
    "        wer = calculate_wer_custom(truth, recognized_text)\n",
    "        print(f\"Reference: {truth}\")\n",
    "        print(f\"Recognized: {recognized_text}\")\n",
    "        print(f\"WER: {wer:.2f}%\")\n",
    "\n",
    "        language_wer[lang.upper()].append(wer)\n",
    "        results.append({\"File\": file, \"Language\": lang.upper(), \"WER\": wer})\n",
    "\n",
    "    print(\"\\n--- Evaluation Results ---\")\n",
    "    for res in results:\n",
    "        print(f\"{res['File']:<30} {res['Language']:<10} {res['WER']:<10.2f}\")\n",
    "\n",
    "    print(\"\\n--- Average WER by Language ---\")\n",
    "    for lang, wer_list in language_wer.items():\n",
    "        avg_wer = sum(wer_list) / len(wer_list) if wer_list else 0\n",
    "        print(f\"{lang}: {avg_wer:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_asr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEPSPEECH(very bad performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Model.__del__ at 0x000001B9B24B70D0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pan shengxin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\vosk\\__init__.py\", line 60, in __del__\n",
      "    _c.vosk_model_free(self._handle)\n",
      "AttributeError: 'Model' object has no attribute '_handle'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Ex4_audio_files/EN/checkin.wav (EN)...\n",
      "Preprocessing Ex4_audio_files/EN/checkin.wav...\n",
      "Analyzing audio for parameter selection...\n",
      "Audio duration (for analysis): 2.76s\n",
      "Detected noise level: -26.64 dBFS\n",
      "RMS dB: -26.64, Peak dB: -12.02, Dynamic Range: 14.62 dB\n",
      "Analysis complete. Parameters chosen:\n",
      "Noise Prop Decrease: 0.2\n",
      "Apply Compression: False, Threshold: None, Ratio: None\n",
      "EQ: Low-pass 3000 Hz, High-pass 200 Hz, Skip EQ: False\n",
      "Loading Ex4_audio_files/EN/checkin.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Converting to mono, adjusting sample rate, and normalizing final audio...\n",
      "Final audio duration: 2.76s\n",
      "Final preprocessed audio saved to preprocessed_checkin.wav, length: 2.76s\n",
      "Processing audio file: preprocessed_checkin.wav\n",
      "Model and scorer loaded successfully.\n",
      "Reference: Where is the check-in desk?\n",
      "Recognized: where is the check in desk\n",
      "WER: 0.0%\n",
      "\n",
      "Processing Ex4_audio_files/EN/parents.wav (EN)...\n",
      "Preprocessing Ex4_audio_files/EN/parents.wav...\n",
      "Analyzing audio for parameter selection...\n",
      "Audio duration (for analysis): 2.55s\n",
      "Detected noise level: -24.96 dBFS\n",
      "RMS dB: -24.95, Peak dB: -11.55, Dynamic Range: 13.41 dB\n",
      "Analysis complete. Parameters chosen:\n",
      "Noise Prop Decrease: 0.2\n",
      "Apply Compression: False, Threshold: None, Ratio: None\n",
      "EQ: Low-pass 3000 Hz, High-pass 200 Hz, Skip EQ: False\n",
      "Loading Ex4_audio_files/EN/parents.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Converting to mono, adjusting sample rate, and normalizing final audio...\n",
      "Final audio duration: 2.55s\n",
      "Final preprocessed audio saved to preprocessed_parents.wav, length: 2.55s\n",
      "Processing audio file: preprocessed_parents.wav\n",
      "Model and scorer loaded successfully.\n",
      "Reference: I have lost my parents.\n",
      "Recognized: i have lost my parents\n",
      "WER: 0.0%\n",
      "\n",
      "Processing Ex4_audio_files/EN/suitcase.wav (EN)...\n",
      "Preprocessing Ex4_audio_files/EN/suitcase.wav...\n",
      "Analyzing audio for parameter selection...\n",
      "Audio duration (for analysis): 2.81s\n",
      "Detected noise level: -25.64 dBFS\n",
      "RMS dB: -25.64, Peak dB: -11.67, Dynamic Range: 13.97 dB\n",
      "Analysis complete. Parameters chosen:\n",
      "Noise Prop Decrease: 0.2\n",
      "Apply Compression: False, Threshold: None, Ratio: None\n",
      "EQ: Low-pass 3000 Hz, High-pass 200 Hz, Skip EQ: False\n",
      "Loading Ex4_audio_files/EN/suitcase.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Converting to mono, adjusting sample rate, and normalizing final audio...\n",
      "Final audio duration: 2.81s\n",
      "Final preprocessed audio saved to preprocessed_suitcase.wav, length: 2.81s\n",
      "Processing audio file: preprocessed_suitcase.wav\n",
      "Model and scorer loaded successfully.\n",
      "Reference: Please, I have lost my suitcase.\n",
      "Recognized: please i lost my suitcase\n",
      "WER: 16.67%\n",
      "\n",
      "Processing Ex4_audio_files/EN/what_time.wav (EN)...\n",
      "Preprocessing Ex4_audio_files/EN/what_time.wav...\n",
      "Analyzing audio for parameter selection...\n",
      "Audio duration (for analysis): 1.85s\n",
      "Detected noise level: -25.14 dBFS\n",
      "RMS dB: -25.13, Peak dB: -11.78, Dynamic Range: 13.35 dB\n",
      "Analysis complete. Parameters chosen:\n",
      "Noise Prop Decrease: 0.2\n",
      "Apply Compression: False, Threshold: None, Ratio: None\n",
      "EQ: Low-pass 3000 Hz, High-pass 200 Hz, Skip EQ: False\n",
      "Loading Ex4_audio_files/EN/what_time.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Converting to mono, adjusting sample rate, and normalizing final audio...\n",
      "Final audio duration: 1.85s\n",
      "Final preprocessed audio saved to preprocessed_what_time.wav, length: 1.85s\n",
      "Processing audio file: preprocessed_what_time.wav\n",
      "Model and scorer loaded successfully.\n",
      "Reference: What time is my plane?\n",
      "Recognized: what time is my plain\n",
      "WER: 20.0%\n",
      "\n",
      "Processing Ex4_audio_files/EN/where.wav (EN)...\n",
      "Preprocessing Ex4_audio_files/EN/where.wav...\n",
      "Analyzing audio for parameter selection...\n",
      "Audio duration (for analysis): 2.65s\n",
      "Detected noise level: -25.11 dBFS\n",
      "RMS dB: -25.11, Peak dB: -12.68, Dynamic Range: 12.43 dB\n",
      "Analysis complete. Parameters chosen:\n",
      "Noise Prop Decrease: 0.2\n",
      "Apply Compression: False, Threshold: None, Ratio: None\n",
      "EQ: Low-pass 3000 Hz, High-pass 200 Hz, Skip EQ: False\n",
      "Loading Ex4_audio_files/EN/where.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Converting to mono, adjusting sample rate, and normalizing final audio...\n",
      "Final audio duration: 2.65s\n",
      "Final preprocessed audio saved to preprocessed_where.wav, length: 2.65s\n",
      "Processing audio file: preprocessed_where.wav\n",
      "Model and scorer loaded successfully.\n",
      "Reference: Where are the restaurants and shops?\n",
      "Recognized: where are the restaurants and shops\n",
      "WER: 0.0%\n",
      "\n",
      "Processing Ex4_audio_files/IT/checkin_it.wav (IT)...\n",
      "Preprocessing Ex4_audio_files/IT/checkin_it.wav...\n",
      "Analyzing audio for parameter selection...\n",
      "Audio duration (for analysis): 1.50s\n",
      "Detected noise level: -22.41 dBFS\n",
      "RMS dB: -22.41, Peak dB: -8.07, Dynamic Range: 14.34 dB\n",
      "Analysis complete. Parameters chosen:\n",
      "Noise Prop Decrease: 0.2\n",
      "Apply Compression: False, Threshold: None, Ratio: None\n",
      "EQ: Low-pass 3000 Hz, High-pass 200 Hz, Skip EQ: False\n",
      "Loading Ex4_audio_files/IT/checkin_it.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Converting to mono, adjusting sample rate, and normalizing final audio...\n",
      "Final audio duration: 1.50s\n",
      "Final preprocessed audio saved to preprocessed_checkin_it.wav, length: 1.50s\n",
      "Processing audio file: preprocessed_checkin_it.wav\n",
      "Model and scorer loaded successfully.\n",
      "Reference: Dove e' il bancone?\n",
      "Recognized: dove e il pancone\n",
      "WER: 25.0%\n",
      "\n",
      "Processing Ex4_audio_files/IT/parents_it.wav (IT)...\n",
      "Preprocessing Ex4_audio_files/IT/parents_it.wav...\n",
      "Analyzing audio for parameter selection...\n",
      "Audio duration (for analysis): 1.40s\n",
      "Detected noise level: -23.50 dBFS\n",
      "RMS dB: -23.50, Peak dB: -6.28, Dynamic Range: 17.22 dB\n",
      "Analysis complete. Parameters chosen:\n",
      "Noise Prop Decrease: 0.2\n",
      "Apply Compression: False, Threshold: None, Ratio: None\n",
      "EQ: Low-pass 3000 Hz, High-pass 200 Hz, Skip EQ: False\n",
      "Loading Ex4_audio_files/IT/parents_it.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Converting to mono, adjusting sample rate, and normalizing final audio...\n",
      "Final audio duration: 1.41s\n",
      "Final preprocessed audio saved to preprocessed_parents_it.wav, length: 1.41s\n",
      "Processing audio file: preprocessed_parents_it.wav\n",
      "Model and scorer loaded successfully.\n",
      "Reference: Ho perso i miei genitori.\n",
      "Recognized: perso i miei genitori\n",
      "WER: 20.0%\n",
      "\n",
      "Processing Ex4_audio_files/IT/suitcase_it.wav (IT)...\n",
      "Preprocessing Ex4_audio_files/IT/suitcase_it.wav...\n",
      "Analyzing audio for parameter selection...\n",
      "Audio duration (for analysis): 2.09s\n",
      "Detected noise level: -24.81 dBFS\n",
      "RMS dB: -24.81, Peak dB: -5.93, Dynamic Range: 18.88 dB\n",
      "Analysis complete. Parameters chosen:\n",
      "Noise Prop Decrease: 0.2\n",
      "Apply Compression: True, Threshold: -22.0, Ratio: 1.2\n",
      "EQ: Low-pass 3000 Hz, High-pass 200 Hz, Skip EQ: False\n",
      "Loading Ex4_audio_files/IT/suitcase_it.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Compressing and amplifying speech in temp_noise_reduced.wav...\n",
      "Compressed and amplified audio saved to temp_compressed.wav\n",
      "Applying equalization to temp_compressed.wav...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Converting to mono, adjusting sample rate, and normalizing final audio...\n",
      "Final audio duration: 2.09s\n",
      "Final preprocessed audio saved to preprocessed_suitcase_it.wav, length: 2.09s\n",
      "Processing audio file: preprocessed_suitcase_it.wav\n",
      "Model and scorer loaded successfully.\n",
      "Reference: Per favore, ho perso la mia valigia.\n",
      "Recognized: per favore ho perso la mia valigia\n",
      "WER: 0.0%\n",
      "\n",
      "Processing Ex4_audio_files/IT/what_time_it.wav (IT)...\n",
      "Preprocessing Ex4_audio_files/IT/what_time_it.wav...\n",
      "Audio is too short and may be too fast. Slowing down...\n",
      "Processed audio saved to temp_slowed.wav\n",
      "Analyzing audio for parameter selection...\n",
      "Audio duration (for analysis): 1.45s\n",
      "Detected noise level: -24.61 dBFS\n",
      "RMS dB: -24.61, Peak dB: -6.88, Dynamic Range: 17.73 dB\n",
      "Analysis complete. Parameters chosen:\n",
      "Noise Prop Decrease: 0.2\n",
      "Apply Compression: False, Threshold: None, Ratio: None\n",
      "EQ: Low-pass 3000 Hz, High-pass 200 Hz, Skip EQ: False\n",
      "Loading temp_slowed.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Converting to mono, adjusting sample rate, and normalizing final audio...\n",
      "Final audio duration: 1.45s\n",
      "Final preprocessed audio saved to preprocessed_what_time_it.wav, length: 1.45s\n",
      "Processing audio file: preprocessed_what_time_it.wav\n",
      "Model and scorer loaded successfully.\n",
      "Reference: A che ora e' il mio aereo?\n",
      "Recognized: e\n",
      "WER: 75.71%\n",
      "\n",
      "Processing Ex4_audio_files/IT/where_it.wav (IT)...\n",
      "Preprocessing Ex4_audio_files/IT/where_it.wav...\n",
      "Analyzing audio for parameter selection...\n",
      "Audio duration (for analysis): 2.04s\n",
      "Detected noise level: -22.31 dBFS\n",
      "RMS dB: -22.31, Peak dB: -5.95, Dynamic Range: 16.35 dB\n",
      "Analysis complete. Parameters chosen:\n",
      "Noise Prop Decrease: 0.2\n",
      "Apply Compression: False, Threshold: None, Ratio: None\n",
      "EQ: Low-pass 3000 Hz, High-pass 200 Hz, Skip EQ: False\n",
      "Loading Ex4_audio_files/IT/where_it.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Converting to mono, adjusting sample rate, and normalizing final audio...\n",
      "Final audio duration: 2.04s\n",
      "Final preprocessed audio saved to preprocessed_where_it.wav, length: 2.04s\n",
      "Processing audio file: preprocessed_where_it.wav\n",
      "Model and scorer loaded successfully.\n",
      "Reference: Dove sono i ristoranti e i negozi?\n",
      "Recognized: dove sono ristoranti negozi\n",
      "WER: 12.86%\n",
      "\n",
      "Processing Ex4_audio_files/ES/checkin_es.wav (ES)...\n",
      "Preprocessing Ex4_audio_files/ES/checkin_es.wav...\n",
      "Analyzing audio for parameter selection...\n",
      "Audio duration (for analysis): 2.33s\n",
      "Detected noise level: -27.18 dBFS\n",
      "RMS dB: -27.17, Peak dB: -12.08, Dynamic Range: 15.09 dB\n",
      "Analysis complete. Parameters chosen:\n",
      "Noise Prop Decrease: 0.2\n",
      "Apply Compression: False, Threshold: None, Ratio: None\n",
      "EQ: Low-pass 3000 Hz, High-pass 200 Hz, Skip EQ: False\n",
      "Loading Ex4_audio_files/ES/checkin_es.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Converting to mono, adjusting sample rate, and normalizing final audio...\n",
      "Final audio duration: 2.33s\n",
      "Final preprocessed audio saved to preprocessed_checkin_es.wav, length: 2.33s\n",
      "Processing audio file: preprocessed_checkin_es.wav\n",
      "Model and scorer loaded successfully.\n",
      "Reference: ¿Dónde están los mostradores?\n",
      "Recognized: adande estan los mostradores\n",
      "WER: 25.0%\n",
      "\n",
      "Processing Ex4_audio_files/ES/parents_es.wav (ES)...\n",
      "Preprocessing Ex4_audio_files/ES/parents_es.wav...\n",
      "Analyzing audio for parameter selection...\n",
      "Audio duration (for analysis): 2.26s\n",
      "Detected noise level: -25.11 dBFS\n",
      "RMS dB: -25.11, Peak dB: -8.75, Dynamic Range: 16.36 dB\n",
      "Analysis complete. Parameters chosen:\n",
      "Noise Prop Decrease: 0.2\n",
      "Apply Compression: False, Threshold: None, Ratio: None\n",
      "EQ: Low-pass 3000 Hz, High-pass 200 Hz, Skip EQ: False\n",
      "Loading Ex4_audio_files/ES/parents_es.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Converting to mono, adjusting sample rate, and normalizing final audio...\n",
      "Final audio duration: 2.26s\n",
      "Final preprocessed audio saved to preprocessed_parents_es.wav, length: 2.26s\n",
      "Processing audio file: preprocessed_parents_es.wav\n",
      "Model and scorer loaded successfully.\n",
      "Reference: He perdido a mis padres.\n",
      "Recognized: he perdido a mis padres\n",
      "WER: 0.0%\n",
      "\n",
      "Processing Ex4_audio_files/ES/suitcase_es.wav (ES)...\n",
      "Preprocessing Ex4_audio_files/ES/suitcase_es.wav...\n",
      "Analyzing audio for parameter selection...\n",
      "Audio duration (for analysis): 2.65s\n",
      "Detected noise level: -24.76 dBFS\n",
      "RMS dB: -24.75, Peak dB: -9.01, Dynamic Range: 15.75 dB\n",
      "Analysis complete. Parameters chosen:\n",
      "Noise Prop Decrease: 0.2\n",
      "Apply Compression: False, Threshold: None, Ratio: None\n",
      "EQ: Low-pass 3000 Hz, High-pass 200 Hz, Skip EQ: False\n",
      "Loading Ex4_audio_files/ES/suitcase_es.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Converting to mono, adjusting sample rate, and normalizing final audio...\n",
      "Final audio duration: 2.65s\n",
      "Final preprocessed audio saved to preprocessed_suitcase_es.wav, length: 2.65s\n",
      "Processing audio file: preprocessed_suitcase_es.wav\n",
      "Model and scorer loaded successfully.\n",
      "Reference: Por favor, he perdido mi maleta.\n",
      "Recognized: por favor he perdido mi maleta\n",
      "WER: 0.0%\n",
      "\n",
      "Processing Ex4_audio_files/ES/what_time_es.wav (ES)...\n",
      "Preprocessing Ex4_audio_files/ES/what_time_es.wav...\n",
      "Analyzing audio for parameter selection...\n",
      "Audio duration (for analysis): 1.96s\n",
      "Detected noise level: -27.39 dBFS\n",
      "RMS dB: -27.39, Peak dB: -11.64, Dynamic Range: 15.75 dB\n",
      "Analysis complete. Parameters chosen:\n",
      "Noise Prop Decrease: 0.2\n",
      "Apply Compression: False, Threshold: None, Ratio: None\n",
      "EQ: Low-pass 3000 Hz, High-pass 200 Hz, Skip EQ: False\n",
      "Loading Ex4_audio_files/ES/what_time_es.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Converting to mono, adjusting sample rate, and normalizing final audio...\n",
      "Final audio duration: 1.96s\n",
      "Final preprocessed audio saved to preprocessed_what_time_es.wav, length: 1.96s\n",
      "Processing audio file: preprocessed_what_time_es.wav\n",
      "Model and scorer loaded successfully.\n",
      "Reference: ¿A qué hora es mi avión?\n",
      "Recognized: la ira es miedo\n",
      "WER: 71.67%\n",
      "\n",
      "Processing Ex4_audio_files/ES/where_es.wav (ES)...\n",
      "Preprocessing Ex4_audio_files/ES/where_es.wav...\n",
      "Analyzing audio for parameter selection...\n",
      "Audio duration (for analysis): 3.26s\n",
      "Detected noise level: -28.18 dBFS\n",
      "RMS dB: -28.17, Peak dB: -13.05, Dynamic Range: 15.12 dB\n",
      "Analysis complete. Parameters chosen:\n",
      "Noise Prop Decrease: 0.2\n",
      "Apply Compression: False, Threshold: None, Ratio: None\n",
      "EQ: Low-pass 3000 Hz, High-pass 200 Hz, Skip EQ: False\n",
      "Loading Ex4_audio_files/ES/where_es.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Converting to mono, adjusting sample rate, and normalizing final audio...\n",
      "Final audio duration: 3.26s\n",
      "Final preprocessed audio saved to preprocessed_where_es.wav, length: 3.26s\n",
      "Processing audio file: preprocessed_where_es.wav\n",
      "Model and scorer loaded successfully.\n",
      "Reference: ¿Dónde están los restaurantes y las tiendas?\n",
      "Recognized: adande estan los restaurantes en las tiendas\n",
      "WER: 18.57%\n",
      "\n",
      "--- Evaluation Results ---\n",
      "File                           Language   WER (%)   \n",
      "Ex4_audio_files/EN/checkin.wav EN         0.0       \n",
      "Ex4_audio_files/EN/parents.wav EN         0.0       \n",
      "Ex4_audio_files/EN/suitcase.wav EN         16.67     \n",
      "Ex4_audio_files/EN/what_time.wav EN         20.0      \n",
      "Ex4_audio_files/EN/where.wav   EN         0.0       \n",
      "Ex4_audio_files/IT/checkin_it.wav IT         25.0      \n",
      "Ex4_audio_files/IT/parents_it.wav IT         20.0      \n",
      "Ex4_audio_files/IT/suitcase_it.wav IT         0.0       \n",
      "Ex4_audio_files/IT/what_time_it.wav IT         75.71     \n",
      "Ex4_audio_files/IT/where_it.wav IT         12.86     \n",
      "Ex4_audio_files/ES/checkin_es.wav ES         25.0      \n",
      "Ex4_audio_files/ES/parents_es.wav ES         0.0       \n",
      "Ex4_audio_files/ES/suitcase_es.wav ES         0.0       \n",
      "Ex4_audio_files/ES/what_time_es.wav ES         71.67     \n",
      "Ex4_audio_files/ES/where_es.wav ES         18.57     \n",
      "\n",
      "--- Average WER by Language ---\n",
      "EN: 7.33%\n",
      "IT: 26.71%\n",
      "ES: 23.05%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import deepspeech\n",
    "import wave\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import json\n",
    "import jiwer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from pydub import AudioSegment, effects\n",
    "import numpy as np\n",
    "import re\n",
    "import noisereduce as nr\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "import librosa.effects\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import wiener\n",
    "import unicodedata\n",
    "from langdetect import detect\n",
    "import language_tool_python\n",
    "\n",
    "\n",
    "# Time-stretching to slow down audio without affecting pitch\n",
    "def slow_down_preserving_pitch(input_file, output_file, stretch_factor=0.7):\n",
    "    \"\"\"\n",
    "    Slows down audio while preserving pitch using librosa's time_stretch.\n",
    "    - stretch_factor: Less than 1 slows down; greater than 1 speeds up.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(input_file, sr=None)\n",
    "        y_slowed = librosa.effects.time_stretch(y, rate=stretch_factor)\n",
    "        sf.write(output_file, y_slowed, sr)\n",
    "        print(f\"Processed audio saved to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in slowing down audio: {e}\")\n",
    "        sf.write(output_file, y, sr)\n",
    "\n",
    "\n",
    "# Noise reduction (adaptive approach)\n",
    "def adaptive_noise_reduction(input_file, output_file, prop_decrease):\n",
    "    print(f\"Loading {input_file} for adaptive noise reduction...\")\n",
    "    try:\n",
    "        y, sr = librosa.load(input_file, sr=16000)\n",
    "        if len(y) == 0:\n",
    "            print(\"Warning: Input audio is empty. Copying as is.\")\n",
    "            sf.write(output_file, y, sr)\n",
    "            return output_file\n",
    "\n",
    "        noise_profile = y[:int(sr * 0.5)]  # Use first 0.5 seconds for noise profile\n",
    "        y_denoised = nr.reduce_noise(y=y, y_noise=noise_profile, sr=sr, prop_decrease=prop_decrease)\n",
    "        sf.write(output_file, y_denoised, sr)\n",
    "        print(f\"Noise-reduced audio saved to {output_file}\")\n",
    "        return output_file\n",
    "    except Exception as e:\n",
    "        print(f\"Error in noise reduction: {e}\")\n",
    "        return input_file\n",
    "\n",
    "# Compression and amplification\n",
    "def compress_and_amplify(input_file, output_file, threshold, ratio):\n",
    "    print(f\"Compressing and amplifying speech in {input_file}...\")\n",
    "    try:\n",
    "        if not os.path.exists(input_file):\n",
    "            print(\"Error: Input file does not exist for compression.\")\n",
    "            return None\n",
    "\n",
    "        audio = AudioSegment.from_wav(input_file)\n",
    "        if len(audio) == 0:\n",
    "            print(\"Warning: Audio is empty during compression. Copying as is.\")\n",
    "            audio.export(output_file, format=\"wav\")\n",
    "            return output_file\n",
    "\n",
    "        compressed_audio = effects.compress_dynamic_range(\n",
    "            audio,\n",
    "            threshold=threshold,\n",
    "            ratio=ratio,\n",
    "            attack=20.0,\n",
    "            release=100.0\n",
    "        )\n",
    "\n",
    "        normalized_audio = effects.normalize(compressed_audio)\n",
    "        normalized_audio.export(output_file, format=\"wav\")\n",
    "        print(f\"Compressed and amplified audio saved to {output_file}\")\n",
    "        return output_file\n",
    "    except Exception as e:\n",
    "        print(f\"Error in compression and amplification: {e}\")\n",
    "        return input_file\n",
    "\n",
    "# Equalization\n",
    "def apply_equalization(input_file, output_file, low_pass_cutoff, high_pass_cutoff):\n",
    "    print(f\"Applying equalization to {input_file}...\")\n",
    "    try:\n",
    "        if not os.path.exists(input_file):\n",
    "            print(\"Error: Input file does not exist for EQ.\")\n",
    "            return None\n",
    "\n",
    "        audio = AudioSegment.from_wav(input_file)\n",
    "        if len(audio) == 0:\n",
    "            print(\"Warning: Audio is empty during EQ. Copying as is.\")\n",
    "            audio.export(output_file, format=\"wav\")\n",
    "            return output_file\n",
    "\n",
    "        boosted_audio = audio.high_pass_filter(high_pass_cutoff).low_pass_filter(low_pass_cutoff)\n",
    "        boosted_audio.export(output_file, format=\"wav\")\n",
    "        print(f\"Equalized audio saved to {output_file}\")\n",
    "        return output_file\n",
    "    except Exception as e:\n",
    "        print(f\"Error in equalization: {e}\")\n",
    "        return input_file\n",
    "\n",
    "# Analyze audio characteristics\n",
    "def analyze_audio(input_file):\n",
    "    print(\"Analyzing audio for parameter selection...\")\n",
    "    try:\n",
    "        y, sr = librosa.load(input_file, sr=16000, mono=True)\n",
    "        duration = librosa.get_duration(y=y, sr=sr)\n",
    "        print(f\"Audio duration (for analysis): {duration:.2f}s\")\n",
    "\n",
    "        noise_level = detect_noise_level(input_file)\n",
    "\n",
    "        if len(y) > 0:\n",
    "            rms = np.sqrt(np.mean(y**2))\n",
    "            peak = np.max(np.abs(y))\n",
    "        else:\n",
    "            rms = 0\n",
    "            peak = 0\n",
    "\n",
    "        rms_db = 20 * np.log10(rms) if rms > 0 else -100\n",
    "        peak_db = 20 * np.log10(peak) if peak > 0 else -100\n",
    "        dynamic_range = peak_db - rms_db\n",
    "        print(f\"RMS dB: {rms_db:.2f}, Peak dB: {peak_db:.2f}, Dynamic Range: {dynamic_range:.2f} dB\")\n",
    "\n",
    "        # Frequency analysis for EQ decisions\n",
    "        if len(y) > 0:\n",
    "            S = np.abs(librosa.stft(y, n_fft=1024, hop_length=512))\n",
    "            freqs = librosa.fft_frequencies(sr=sr, n_fft=1024)\n",
    "            low_freq_mask = freqs < 300\n",
    "            high_freq_mask = freqs > 3000\n",
    "\n",
    "            low_energy = np.mean(S[low_freq_mask, :]) if np.any(low_freq_mask) else 0\n",
    "            high_energy = np.mean(S[high_freq_mask, :]) if np.any(high_freq_mask) else 0\n",
    "            mean_energy = np.mean(S)\n",
    "        else:\n",
    "            low_energy = 0\n",
    "            high_energy = 0\n",
    "            mean_energy = 0\n",
    "\n",
    "        # Adjust noise reduction settings for short audio\n",
    "        if noise_level > -25:\n",
    "            noise_prop_decrease = 0.3 # Stronger noise reduction for very noisy audio\n",
    "        elif noise_level > -35:\n",
    "            noise_prop_decrease = 0.2 # Moderate noise reduction\n",
    "        else:\n",
    "            noise_prop_decrease = 0.1  # Light noise reduction for clean audio\n",
    "\n",
    "        # Adjust compression logic for short but valid audio\n",
    "        if dynamic_range > 18 and duration > 3.0:\n",
    "            apply_compression = True\n",
    "            comp_threshold = -25.0\n",
    "            comp_ratio = 1.5\n",
    "        elif dynamic_range > 18 and duration <= 3.0:\n",
    "            apply_compression = True\n",
    "            comp_threshold = -22.0  # Lower threshold for shorter audio\n",
    "            comp_ratio = 1.2  # Slightly weaker compression\n",
    "        else:\n",
    "            apply_compression = False\n",
    "            comp_threshold = None\n",
    "            comp_ratio = None\n",
    "\n",
    "         # Refined EQ logic for short audio\n",
    "        if mean_energy > 0:\n",
    "            if low_energy > (mean_energy * 1.5):\n",
    "                high_pass_cutoff = 200\n",
    "            else:\n",
    "                high_pass_cutoff = 100\n",
    "\n",
    "            if high_energy > (mean_energy * 1.5):\n",
    "                low_pass_cutoff = 3500\n",
    "            else:\n",
    "                low_pass_cutoff = 3000\n",
    "        else:\n",
    "            high_pass_cutoff = 100\n",
    "            low_pass_cutoff = 2000\n",
    "\n",
    "        # Adjust for short audio (2–3 seconds)\n",
    "        if duration < 3.0:\n",
    "            skip_eq = False  # Apply EQ since audio is valid for full processing\n",
    "            noise_prop_decrease = 0.2  # Moderate noise reduction\n",
    "        else:\n",
    "            skip_eq = False  # Always process EQ for longer audio\n",
    "\n",
    "        # Skip EQ for clean audio with very low noise\n",
    "        if noise_level < -30:\n",
    "            skip_eq = True\n",
    "\n",
    "        print(\"Analysis complete. Parameters chosen:\")\n",
    "        print(f\"Noise Prop Decrease: {noise_prop_decrease}\")\n",
    "        print(f\"Apply Compression: {apply_compression}, Threshold: {comp_threshold}, Ratio: {comp_ratio}\")\n",
    "        print(f\"EQ: Low-pass {low_pass_cutoff} Hz, High-pass {high_pass_cutoff} Hz, Skip EQ: {skip_eq}\")\n",
    "\n",
    "        return {\n",
    "            'noise_prop_decrease': noise_prop_decrease,\n",
    "            'apply_compression': apply_compression,\n",
    "            'comp_threshold': comp_threshold,\n",
    "            'comp_ratio': comp_ratio,\n",
    "            'high_pass_cutoff': high_pass_cutoff,\n",
    "            'low_pass_cutoff': low_pass_cutoff,\n",
    "            'skip_eq': skip_eq\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error in analyzing audio: {e}\")\n",
    "        return {\n",
    "            'noise_prop_decrease': 0.2,\n",
    "            'apply_compression': False,\n",
    "            'comp_threshold': None,\n",
    "            'comp_ratio': None,\n",
    "            'high_pass_cutoff': 200,\n",
    "            'low_pass_cutoff': 3000,\n",
    "            'skip_eq': True\n",
    "        }\n",
    "\n",
    "# Noise level detection\n",
    "def detect_noise_level(input_file):\n",
    "    try:\n",
    "        audio = AudioSegment.from_wav(input_file)\n",
    "        noise_level = audio.dBFS\n",
    "        print(f\"Detected noise level: {noise_level:.2f} dBFS\")\n",
    "        return noise_level\n",
    "    except Exception as e:\n",
    "        print(f\"Error in detecting noise level: {e}\")\n",
    "        return -100\n",
    "\n",
    "# Preprocess audio pipeline\n",
    "def preprocess_audio(input_file, output_file):\n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"Error: File {input_file} does not exist.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Preprocessing {input_file}...\")\n",
    "\n",
    "    try:\n",
    "        # Load audio and check duration\n",
    "        audio = AudioSegment.from_wav(input_file)\n",
    "        audio_duration = len(audio) / 1000.0  # Convert from ms to seconds\n",
    "\n",
    "        if audio_duration < 1.4:\n",
    "            print(\"Audio is too short and may be too fast. Slowing down...\")\n",
    "            temp_slowed_file = \"temp_slowed.wav\"\n",
    "            slow_down_preserving_pitch(input_file, temp_slowed_file, stretch_factor=0.85)\n",
    "            input_file = temp_slowed_file  # Update input file to the slowed version\n",
    "\n",
    "        # Reanalyze audio after slowing down (if applicable)\n",
    "        params = analyze_audio(input_file)\n",
    "\n",
    "        # Perform noise reduction\n",
    "        noise_reduced_file = \"temp_noise_reduced.wav\"\n",
    "        adaptive_noise_reduction(input_file, noise_reduced_file, params['noise_prop_decrease'])\n",
    "\n",
    "        processed_file = noise_reduced_file\n",
    "\n",
    "        # Apply compression if needed\n",
    "        if params['apply_compression']:\n",
    "            compressed_file = \"temp_compressed.wav\"\n",
    "            compress_and_amplify(processed_file, compressed_file, params['comp_threshold'], params['comp_ratio'])\n",
    "            processed_file = compressed_file\n",
    "\n",
    "        # Apply EQ if not skipped\n",
    "        if not params['skip_eq']:\n",
    "            equalized_file = \"temp_equalized.wav\"\n",
    "            apply_equalization(processed_file, equalized_file, params['low_pass_cutoff'], params['high_pass_cutoff'])\n",
    "            processed_file = equalized_file\n",
    "\n",
    "        # Convert to mono, 16kHz, and normalize at the end\n",
    "        print(\"Converting to mono, adjusting sample rate, and normalizing final audio...\")\n",
    "        if not os.path.exists(processed_file):\n",
    "            print(\"Error: Processed file does not exist, aborting.\")\n",
    "            return None\n",
    "\n",
    "        final_audio = AudioSegment.from_wav(processed_file).set_channels(1).set_frame_rate(16000)\n",
    "        final_audio = effects.normalize(final_audio)\n",
    "\n",
    "        final_length = len(final_audio) / 1000.0\n",
    "        print(f\"Final audio duration: {final_length:.2f}s\")\n",
    "\n",
    "        final_audio.export(output_file, format=\"wav\")\n",
    "        print(f\"Final preprocessed audio saved to {output_file}, length: {final_length:.2f}s\")\n",
    "\n",
    "        return output_file\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing audio: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to transcribe using DeepSpeech\n",
    "def transcribe_deepspeech(audio_file, model_path, scorer_path):\n",
    "    print(f\"Processing audio file: {audio_file}\")\n",
    "    ds = deepspeech.Model(model_path)\n",
    "    ds.enableExternalScorer(scorer_path)\n",
    "    print(\"Model and scorer loaded successfully.\")\n",
    "\n",
    "    with wave.open(audio_file, 'rb') as wf:\n",
    "        # Verify WAV file properties\n",
    "        if wf.getsampwidth() != 2:\n",
    "            raise ValueError(\"Audio file must be 16-bit PCM.\")\n",
    "        if wf.getnchannels() != 1:\n",
    "            raise ValueError(\"Audio file must be mono.\")\n",
    "        if wf.getframerate() != 16000:\n",
    "            raise ValueError(\"Audio file must have a sample rate of 16 kHz.\")\n",
    "\n",
    "        frames = wf.readframes(wf.getnframes())\n",
    "        audio_data = np.frombuffer(frames, dtype=np.int16)\n",
    "\n",
    "    text = ds.stt(audio_data)\n",
    "    return text\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Normalizes text by:\n",
    "    - Converting to lowercase\n",
    "    - Replacing hyphens with spaces (to separate compound words)\n",
    "    - Removing other punctuation\n",
    "    - Removing accents from characters\n",
    "    \"\"\"\n",
    "    # Convert all text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace hyphens with spaces to separate words\n",
    "    text = re.sub(r\"-\", \" \", text)\n",
    "    \n",
    "    # Remove remaining punctuation, except for word and space characters\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    \n",
    "    # Remove accents from characters\n",
    "    # Normalize to NFD to separate accents, then remove them\n",
    "    text = unicodedata.normalize('NFD', text)\n",
    "    text = \"\".join([c for c in text if unicodedata.category(c) != 'Mn'])\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def calculate_wer_custom(reference, hypothesis):\n",
    "    \"\"\"\n",
    "    Calculates Word Error Rate (WER) with normalization applied,\n",
    "    ensuring minor impact for single-letter words and better handling of deletions and insertions.\n",
    "    \"\"\"\n",
    "    # Normalize both reference and hypothesis\n",
    "    reference = normalize_text(reference)\n",
    "    hypothesis = normalize_text(hypothesis)\n",
    "\n",
    "    # Tokenize into words\n",
    "    reference_words = reference.split()\n",
    "    hypothesis_words = hypothesis.split()\n",
    "\n",
    "    # Initialize substitution, deletion, and insertion counters\n",
    "    substitutions, deletions, insertions = 0, 0, 0\n",
    "\n",
    "    # Align reference and hypothesis words using dynamic programming (Levenshtein distance)\n",
    "    ref_len, hyp_len = len(reference_words), len(hypothesis_words)\n",
    "    dp = [[0] * (hyp_len + 1) for _ in range(ref_len + 1)]\n",
    "\n",
    "    # Fill the DP table\n",
    "    for i in range(ref_len + 1):\n",
    "        for j in range(hyp_len + 1):\n",
    "            if i == 0:\n",
    "                dp[i][j] = j  # All insertions\n",
    "            elif j == 0:\n",
    "                dp[i][j] = i  # All deletions\n",
    "            elif reference_words[i - 1] == hypothesis_words[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]  # No penalty for a match\n",
    "            else:\n",
    "                # Assign weights: 0.3 for single-letter mismatches, 1 for others\n",
    "                subst_cost = (\n",
    "                    0.3\n",
    "                    if len(reference_words[i - 1]) == 1 or len(hypothesis_words[j - 1]) == 1\n",
    "                    else 1\n",
    "                )\n",
    "                dp[i][j] = min(\n",
    "                    dp[i - 1][j - 1] + subst_cost,  # Substitution\n",
    "                    dp[i - 1][j] + 1,  # Deletion\n",
    "                    dp[i][j - 1] + 1,  # Insertion\n",
    "                )\n",
    "\n",
    "    # Backtrack to count substitutions, deletions, and insertions\n",
    "    i, j = ref_len, hyp_len\n",
    "    while i > 0 and j > 0:\n",
    "        if reference_words[i - 1] == hypothesis_words[j - 1]:\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif dp[i][j] == dp[i - 1][j - 1] + (\n",
    "            0.3 if len(reference_words[i - 1]) == 1 or len(hypothesis_words[j - 1]) == 1 else 1\n",
    "        ):\n",
    "            substitutions += 0.3 if len(reference_words[i - 1]) == 1 or len(hypothesis_words[j - 1]) == 1 else 1\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif dp[i][j] == dp[i - 1][j] + 1:\n",
    "            deletions += 0.3 if len(reference_words[i - 1]) == 1 else 1\n",
    "            i -= 1\n",
    "        else:\n",
    "            insertions += 0.3 if len(hypothesis_words[j - 1]) == 1 else 1\n",
    "            j -= 1\n",
    "\n",
    "    # Handle remaining deletions and insertions\n",
    "    while i > 0:\n",
    "        deletions += 0.3 if len(reference_words[i - 1]) == 1 else 1\n",
    "        i -= 1\n",
    "    while j > 0:\n",
    "        insertions += 0.3 if len(hypothesis_words[j - 1]) == 1 else 1\n",
    "        j -= 1\n",
    "\n",
    "    # Calculate WER\n",
    "    reference_length = len(reference_words)\n",
    "\n",
    "    # Handle edge case for empty reference\n",
    "    if reference_length == 0:\n",
    "        return 100.0 if substitutions + deletions + insertions > 0 else 0.0\n",
    "\n",
    "    wer = ((substitutions + deletions + insertions) / reference_length) * 100\n",
    "    return round(wer, 2)\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_asr():\n",
    "    audio_files = [\n",
    "        {\"file\": \"Ex4_audio_files/EN/checkin.wav\", \"lang\": \"en\", \"truth\": \"Where is the check-in desk?\"},\n",
    "        {\"file\": \"Ex4_audio_files/EN/parents.wav\", \"lang\": \"en\", \"truth\": \"I have lost my parents.\"},\n",
    "        {\"file\": \"Ex4_audio_files/EN/suitcase.wav\", \"lang\": \"en\", \"truth\": \"Please, I have lost my suitcase.\"},\n",
    "        {\"file\": \"Ex4_audio_files/EN/what_time.wav\", \"lang\": \"en\", \"truth\": \"What time is my plane?\"},\n",
    "        {\"file\": \"Ex4_audio_files/EN/where.wav\", \"lang\": \"en\", \"truth\": \"Where are the restaurants and shops?\"},\n",
    "        \n",
    "        {\"file\": \"Ex4_audio_files/IT/checkin_it.wav\", \"lang\": \"it\", \"truth\": \"Dove e' il bancone?\"},\n",
    "        {\"file\": \"Ex4_audio_files/IT/parents_it.wav\", \"lang\": \"it\", \"truth\": \"Ho perso i miei genitori.\"},\n",
    "        {\"file\": \"Ex4_audio_files/IT/suitcase_it.wav\", \"lang\": \"it\", \"truth\": \"Per favore, ho perso la mia valigia.\"},\n",
    "        {\"file\": \"Ex4_audio_files/IT/what_time_it.wav\", \"lang\": \"it\", \"truth\": \"A che ora e' il mio aereo?\"},\n",
    "        {\"file\": \"Ex4_audio_files/IT/where_it.wav\", \"lang\": \"it\", \"truth\": \"Dove sono i ristoranti e i negozi?\"},\n",
    "\n",
    "        {\"file\": \"Ex4_audio_files/ES/checkin_es.wav\", \"lang\": \"es\", \"truth\": \"¿Dónde están los mostradores?\"},\n",
    "        {\"file\": \"Ex4_audio_files/ES/parents_es.wav\", \"lang\": \"es\", \"truth\": \"He perdido a mis padres.\"},\n",
    "        {\"file\": \"Ex4_audio_files/ES/suitcase_es.wav\", \"lang\": \"es\", \"truth\": \"Por favor, he perdido mi maleta.\"},\n",
    "        {\"file\": \"Ex4_audio_files/ES/what_time_es.wav\", \"lang\": \"es\", \"truth\": \"¿A qué hora es mi avión?\"},\n",
    "        {\"file\": \"Ex4_audio_files/ES/where_es.wav\", \"lang\": \"es\", \"truth\": \"¿Dónde están los restaurantes y las tiendas?\"}\n",
    "    ]\n",
    "\n",
    "    EN_MODEL = \"models/en/deepspeech-0.9.3-models.pbmm\"\n",
    "    EN_SCORER = \"models/en/deepspeech-0.9.3-models.scorer\"\n",
    "    ES_MODEL = \"models/es/output_graph_es.pbmm\"\n",
    "    ES_SCORER = \"models/es/kenlm_es.scorer\"\n",
    "    IT_MODEL = \"models/it/output_graph_it.pbmm\"\n",
    "    IT_SCORER = \"models/it/kenlm_it.scorer\"\n",
    "\n",
    "    results = []\n",
    "    language_wer = {\"EN\": [], \"IT\": [], \"ES\": []}\n",
    "\n",
    "    for item in audio_files:\n",
    "        file = item[\"file\"]\n",
    "        lang = item[\"lang\"]\n",
    "        truth = item[\"truth\"]\n",
    "\n",
    "        print(f\"\\nProcessing {file} ({lang.upper()})...\")\n",
    "        preprocessed_file = f\"preprocessed_{os.path.basename(file)}\"\n",
    "        recognized_text = \"\"\n",
    "\n",
    "        try:\n",
    "            # Preprocess audio\n",
    "            preprocess_audio(file, preprocessed_file)\n",
    "\n",
    "            # Transcription\n",
    "            if lang == \"en\":\n",
    "                recognized_text = transcribe_deepspeech(preprocessed_file, EN_MODEL, EN_SCORER)\n",
    "            elif lang == \"es\":\n",
    "                recognized_text = transcribe_deepspeech(preprocessed_file, ES_MODEL, ES_SCORER)\n",
    "            elif lang == \"it\":\n",
    "                recognized_text = transcribe_deepspeech(preprocessed_file, IT_MODEL, IT_SCORER)\n",
    "            else:\n",
    "                recognized_text = \"Unsupported Language\"\n",
    "        except Exception as e:\n",
    "            recognized_text = f\"Error: {e}\"\n",
    "\n",
    "        # Calculate WER\n",
    "        wer = calculate_wer_custom(truth, recognized_text)\n",
    "        print(f\"Reference: {truth}\")\n",
    "        print(f\"Recognized: {recognized_text}\")\n",
    "        print(f\"WER: {wer}%\")\n",
    "\n",
    "        # Append WER to language-specific list\n",
    "        language_wer[lang.upper()].append(wer)\n",
    "\n",
    "        results.append({\n",
    "            \"File\": file,\n",
    "            \"Language\": lang.upper(),\n",
    "            \"WER\": wer\n",
    "        })\n",
    "\n",
    "    # Print results\n",
    "    print(\"\\n--- Evaluation Results ---\")\n",
    "    print(f\"{'File':<30} {'Language':<10} {'WER (%)':<10}\")\n",
    "    \n",
    "    for res in results:\n",
    "        print(f\"{res['File']:<30} {res['Language']:<10} {res['WER']:<10}\")\n",
    "\n",
    "    # Calculate and display average WER per language\n",
    "    print(\"\\n--- Average WER by Language ---\")\n",
    "    for lang, wer_list in language_wer.items():\n",
    "        if wer_list:\n",
    "            avg_wer = sum(wer_list) / len(wer_list)\n",
    "            print(f\"{lang}: {avg_wer:.2f}%\")\n",
    "        else:\n",
    "            print(f\"{lang}: No data available.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_asr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# open-ai whisper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-whisper\n",
      "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: tqdm in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from openai-whisper) (4.67.1)\n",
      "Requirement already satisfied: numba in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from openai-whisper) (0.58.1)\n",
      "Requirement already satisfied: torch in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from openai-whisper) (2.4.1)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.7.0-cp38-cp38-win_amd64.whl (798 kB)\n",
      "Collecting more-itertools\n",
      "  Downloading more_itertools-10.5.0-py3-none-any.whl (60 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from openai-whisper) (1.22.3)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\pan shengxin\\appdata\\roaming\\python\\python38\\site-packages (from numba->openai-whisper) (8.5.0)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from numba->openai-whisper) (0.41.1)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\pan shengxin\\appdata\\roaming\\python\\python38\\site-packages (from importlib-metadata->numba->openai-whisper) (3.20.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.12.14)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\pan shengxin\\appdata\\roaming\\python\\python38\\site-packages (from torch->openai-whisper) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch->openai-whisper) (3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch->openai-whisper) (3.16.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch->openai-whisper) (2024.10.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch->openai-whisper) (3.1.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch->openai-whisper) (1.13.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jinja2->torch->openai-whisper) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pan shengxin\\appdata\\roaming\\python\\python38\\site-packages (from tqdm->openai-whisper) (0.4.6)\n",
      "Building wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (PEP 517): started\n",
      "  Building wheel for openai-whisper (PEP 517): finished with status 'done'\n",
      "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803358 sha256=3ca509301f3832fb377f6e4595b5a085f9c9383e5cdfa800f3db862ef0f35da1\n",
      "  Stored in directory: c:\\users\\pan shengxin\\appdata\\local\\pip\\cache\\wheels\\58\\9f\\3f\\657caca5c67b43cb90d168c2061936f3255bc28fef73b752ea\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: tiktoken, more-itertools, openai-whisper\n",
      "Successfully installed more-itertools-10.5.0 openai-whisper-20240930 tiktoken-0.7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 21.1.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\pan shengxin\\appdata\\roaming\\python\\python38\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\pan shengxin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai-whisper\n",
    "!pip install torch torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Ex4_audio_files/EN/checkin.wav (EN)...\n",
      "Preprocessing Ex4_audio_files/EN/checkin.wav...\n",
      "Analyzing audio for parameter selection...\n",
      "Audio duration (for analysis): 2.76s\n",
      "Detected noise level: -26.64 dBFS\n",
      "RMS dB: -26.64, Peak dB: -12.02, Dynamic Range: 14.62 dB\n",
      "Analysis complete. Parameters chosen:\n",
      "Noise Prop Decrease: 0.2\n",
      "Apply Compression: False, Threshold: None, Ratio: None\n",
      "EQ: Low-pass 4500 Hz, High-pass 400 Hz, Skip EQ: False\n",
      "Loading Ex4_audio_files/EN/checkin.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Converting to mono, adjusting sample rate, and normalizing final audio...\n",
      "Final audio duration: 2.76s\n",
      "Final preprocessed audio saved to preprocessed_checkin.wav, length: 2.76s\n",
      "Processing audio file: preprocessed_checkin.wav with Whisper\n",
      "Reference: Where is the check-in desk?\n",
      "Recognized:  Where is the check-in desk?\n",
      "WER: 0.0%\n",
      "\n",
      "Processing Ex4_audio_files/EN/parents.wav (EN)...\n",
      "Preprocessing Ex4_audio_files/EN/parents.wav...\n",
      "Analyzing audio for parameter selection...\n",
      "Audio duration (for analysis): 2.55s\n",
      "Detected noise level: -24.96 dBFS\n",
      "RMS dB: -24.95, Peak dB: -11.55, Dynamic Range: 13.41 dB\n",
      "Analysis complete. Parameters chosen:\n",
      "Noise Prop Decrease: 0.2\n",
      "Apply Compression: False, Threshold: None, Ratio: None\n",
      "EQ: Low-pass 4500 Hz, High-pass 400 Hz, Skip EQ: False\n",
      "Loading Ex4_audio_files/EN/parents.wav for adaptive noise reduction...\n",
      "Noise-reduced audio saved to temp_noise_reduced.wav\n",
      "Applying equalization to temp_noise_reduced.wav...\n",
      "Equalized audio saved to temp_equalized.wav\n",
      "Converting to mono, adjusting sample rate, and normalizing final audio...\n",
      "Final audio duration: 2.55s\n",
      "Final preprocessed audio saved to preprocessed_parents.wav, length: 2.55s\n",
      "Processing audio file: preprocessed_parents.wav with Whisper\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 376\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_wer\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 376\u001b[0m     \u001b[43mevaluate_asr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[49], line 353\u001b[0m, in \u001b[0;36mevaluate_asr\u001b[1;34m()\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     preprocess_audio(file, preprocessed_file)\n\u001b[1;32m--> 353\u001b[0m     recognized_text \u001b[38;5;241m=\u001b[39m \u001b[43mtranscribe_whisper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessed_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    355\u001b[0m     recognized_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[49], line 304\u001b[0m, in \u001b[0;36mtranscribe_whisper\u001b[1;34m(audio_file, model_type)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m     model \u001b[38;5;241m=\u001b[39m whisper\u001b[38;5;241m.\u001b[39mload_model(model_type)\n\u001b[1;32m--> 304\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\pan shengxin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\whisper\\transcribe.py:279\u001b[0m, in \u001b[0;36mtranscribe\u001b[1;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[0m\n\u001b[0;32m    276\u001b[0m mel_segment \u001b[38;5;241m=\u001b[39m pad_or_trim(mel_segment, N_FRAMES)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mto(dtype)\n\u001b[0;32m    278\u001b[0m decode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_tokens[prompt_reset_since:]\n\u001b[1;32m--> 279\u001b[0m result: DecodingResult \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel_segment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(result\u001b[38;5;241m.\u001b[39mtokens)\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_speech_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;66;03m# no voice activity check\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pan shengxin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\whisper\\transcribe.py:195\u001b[0m, in \u001b[0;36mtranscribe.<locals>.decode_with_fallback\u001b[1;34m(segment)\u001b[0m\n\u001b[0;32m    192\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_of\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    194\u001b[0m options \u001b[38;5;241m=\u001b[39m DecodingOptions(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, temperature\u001b[38;5;241m=\u001b[39mt)\n\u001b[1;32m--> 195\u001b[0m decode_result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m needs_fallback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    199\u001b[0m     compression_ratio_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m decode_result\u001b[38;5;241m.\u001b[39mcompression_ratio \u001b[38;5;241m>\u001b[39m compression_ratio_threshold\n\u001b[0;32m    201\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\pan shengxin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pan shengxin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\whisper\\decoding.py:824\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m    822\u001b[0m     options \u001b[38;5;241m=\u001b[39m replace(options, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 824\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mDecodingTask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m single \u001b[38;5;28;01melse\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\pan shengxin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pan shengxin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\whisper\\decoding.py:718\u001b[0m, in \u001b[0;36mDecodingTask.run\u001b[1;34m(self, mel)\u001b[0m\n\u001b[0;32m    715\u001b[0m tokenizer: Tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\n\u001b[0;32m    716\u001b[0m n_audio: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m mel\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 718\u001b[0m audio_features: Tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_audio_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# encoder forward pass\u001b[39;00m\n\u001b[0;32m    719\u001b[0m tokens: Tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_tokens])\u001b[38;5;241m.\u001b[39mrepeat(n_audio, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    721\u001b[0m \u001b[38;5;66;03m# detect language if requested, overwriting the language token\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pan shengxin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\whisper\\decoding.py:655\u001b[0m, in \u001b[0;36mDecodingTask._get_audio_features\u001b[1;34m(self, mel)\u001b[0m\n\u001b[0;32m    653\u001b[0m     audio_features \u001b[38;5;241m=\u001b[39m mel\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 655\u001b[0m     audio_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m audio_features\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m (\n\u001b[0;32m    658\u001b[0m     torch\u001b[38;5;241m.\u001b[39mfloat16 \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mfp16 \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[0;32m    659\u001b[0m ):\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    661\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_features has an incorrect dtype: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maudio_features\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    662\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\pan shengxin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pan shengxin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pan shengxin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\whisper\\model.py:201\u001b[0m, in \u001b[0;36mAudioEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    198\u001b[0m x \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_embedding)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m--> 201\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_post(x)\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\pan shengxin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pan shengxin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pan shengxin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\whisper\\model.py:170\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[1;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn:\n\u001b[0;32m    169\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn_ln(x), xa, kv_cache\u001b[38;5;241m=\u001b[39mkv_cache)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 170\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp_ln\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\pan shengxin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pan shengxin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pan shengxin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\whisper\\model.py:41\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtype(x\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\pan shengxin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\normalization.py:202\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pan shengxin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\functional.py:2576\u001b[0m, in \u001b[0;36mlayer_norm\u001b[1;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[0;32m   2572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[0;32m   2573\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   2574\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[0;32m   2575\u001b[0m     )\n\u001b[1;32m-> 2576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import unicodedata\n",
    "import re\n",
    "import whisper\n",
    "import jiwer\n",
    "from pydub import AudioSegment, effects\n",
    "import noisereduce as nr\n",
    "\n",
    "# Normalize text\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Normalizes text by:\n",
    "    - Converting to lowercase\n",
    "    - Replacing hyphens with spaces (to separate compound words)\n",
    "    - Removing other punctuation\n",
    "    - Removing accents from characters\n",
    "    \"\"\"\n",
    "    # Convert all text to lowercase\n",
    "    text = text.lower()\n",
    "    # Replace hyphens with spaces to separate words\n",
    "    text = re.sub(r\"-\", \" \", text)\n",
    "    # Remove remaining punctuation, except for word and space characters\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    # Remove accents from characters\n",
    "    text = unicodedata.normalize('NFD', text)\n",
    "    text = \"\".join([c for c in text if unicodedata.category(c) != 'Mn'])\n",
    "    return text\n",
    "# Time-stretching to slow down audio without affecting pitch\n",
    "def slow_down_preserving_pitch(input_file, output_file, stretch_factor=0.7):\n",
    "    \"\"\"\n",
    "    Slows down audio while preserving pitch using librosa's time_stretch.\n",
    "    - stretch_factor: Less than 1 slows down; greater than 1 speeds up.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(input_file, sr=None)\n",
    "        y_slowed = librosa.effects.time_stretch(y, rate=stretch_factor)\n",
    "        sf.write(output_file, y_slowed, sr)\n",
    "        print(f\"Processed audio saved to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in slowing down audio: {e}\")\n",
    "        sf.write(output_file, y, sr)\n",
    "\n",
    "\n",
    "\n",
    "# Noise reduction (adaptive approach)\n",
    "def adaptive_noise_reduction(input_file, output_file, prop_decrease):\n",
    "    print(f\"Loading {input_file} for adaptive noise reduction...\")\n",
    "    try:\n",
    "        y, sr = librosa.load(input_file, sr=16000)\n",
    "        if len(y) == 0:\n",
    "            print(\"Warning: Input audio is empty. Copying as is.\")\n",
    "            sf.write(output_file, y, sr)\n",
    "            return output_file\n",
    "\n",
    "        noise_profile = y[:int(sr * 0.5)]  # Use first 0.5 seconds for noise profile\n",
    "        y_denoised = nr.reduce_noise(y=y, y_noise=noise_profile, sr=sr, prop_decrease=prop_decrease)\n",
    "        sf.write(output_file, y_denoised, sr)\n",
    "        print(f\"Noise-reduced audio saved to {output_file}\")\n",
    "        return output_file\n",
    "    except Exception as e:\n",
    "        print(f\"Error in noise reduction: {e}\")\n",
    "        return input_file\n",
    "\n",
    "# Compression and amplification\n",
    "def compress_and_amplify(input_file, output_file, threshold, ratio):\n",
    "    print(f\"Compressing and amplifying speech in {input_file}...\")\n",
    "    try:\n",
    "        if not os.path.exists(input_file):\n",
    "            print(\"Error: Input file does not exist for compression.\")\n",
    "            return None\n",
    "\n",
    "        audio = AudioSegment.from_wav(input_file)\n",
    "        if len(audio) == 0:\n",
    "            print(\"Warning: Audio is empty during compression. Copying as is.\")\n",
    "            audio.export(output_file, format=\"wav\")\n",
    "            return output_file\n",
    "\n",
    "        compressed_audio = effects.compress_dynamic_range(\n",
    "            audio,\n",
    "            threshold=threshold,\n",
    "            ratio=ratio,\n",
    "            attack=20.0,\n",
    "            release=100.0\n",
    "        )\n",
    "\n",
    "        normalized_audio = effects.normalize(compressed_audio)\n",
    "        normalized_audio.export(output_file, format=\"wav\")\n",
    "        print(f\"Compressed and amplified audio saved to {output_file}\")\n",
    "        return output_file\n",
    "    except Exception as e:\n",
    "        print(f\"Error in compression and amplification: {e}\")\n",
    "        return input_file\n",
    "\n",
    "# Equalization\n",
    "def apply_equalization(input_file, output_file, low_pass_cutoff, high_pass_cutoff):\n",
    "    print(f\"Applying equalization to {input_file}...\")\n",
    "    try:\n",
    "        if not os.path.exists(input_file):\n",
    "            print(\"Error: Input file does not exist for EQ.\")\n",
    "            return None\n",
    "\n",
    "        audio = AudioSegment.from_wav(input_file)\n",
    "        if len(audio) == 0:\n",
    "            print(\"Warning: Audio is empty during EQ. Copying as is.\")\n",
    "            audio.export(output_file, format=\"wav\")\n",
    "            return output_file\n",
    "\n",
    "        boosted_audio = audio.high_pass_filter(high_pass_cutoff).low_pass_filter(low_pass_cutoff)\n",
    "        boosted_audio.export(output_file, format=\"wav\")\n",
    "        print(f\"Equalized audio saved to {output_file}\")\n",
    "        return output_file\n",
    "    except Exception as e:\n",
    "        print(f\"Error in equalization: {e}\")\n",
    "        return input_file\n",
    "\n",
    "# Analyze audio characteristics\n",
    "def analyze_audio(input_file):\n",
    "    print(\"Analyzing audio for parameter selection...\")\n",
    "    try:\n",
    "        y, sr = librosa.load(input_file, sr=16000, mono=True)\n",
    "        duration = librosa.get_duration(y=y, sr=sr)\n",
    "        print(f\"Audio duration (for analysis): {duration:.2f}s\")\n",
    "\n",
    "        noise_level = detect_noise_level(input_file)\n",
    "\n",
    "        if len(y) > 0:\n",
    "            rms = np.sqrt(np.mean(y**2))\n",
    "            peak = np.max(np.abs(y))\n",
    "        else:\n",
    "            rms = 0\n",
    "            peak = 0\n",
    "\n",
    "        rms_db = 20 * np.log10(rms) if rms > 0 else -100\n",
    "        peak_db = 20 * np.log10(peak) if peak > 0 else -100\n",
    "        dynamic_range = peak_db - rms_db\n",
    "        print(f\"RMS dB: {rms_db:.2f}, Peak dB: {peak_db:.2f}, Dynamic Range: {dynamic_range:.2f} dB\")\n",
    "\n",
    "        # Frequency analysis for EQ decisions\n",
    "        if len(y) > 0:\n",
    "            S = np.abs(librosa.stft(y, n_fft=1024, hop_length=512))\n",
    "            freqs = librosa.fft_frequencies(sr=sr, n_fft=1024)\n",
    "            low_freq_mask = freqs < 300\n",
    "            high_freq_mask = freqs > 3000\n",
    "\n",
    "            low_energy = np.mean(S[low_freq_mask, :]) if np.any(low_freq_mask) else 0\n",
    "            high_energy = np.mean(S[high_freq_mask, :]) if np.any(high_freq_mask) else 0\n",
    "            mean_energy = np.mean(S)\n",
    "        else:\n",
    "            low_energy = 0\n",
    "            high_energy = 0\n",
    "            mean_energy = 0\n",
    "\n",
    "        # Adjust noise reduction settings for short audio\n",
    "        if noise_level > -25:\n",
    "            noise_prop_decrease = 0.3 # Stronger noise reduction for very noisy audio\n",
    "        elif noise_level > -35:\n",
    "            noise_prop_decrease = 0.2 # Moderate noise reduction\n",
    "        else:\n",
    "            noise_prop_decrease = 0.1  # Light noise reduction for clean audio\n",
    "\n",
    "        # Adjust compression logic for short but valid audio\n",
    "        if dynamic_range > 18 and duration > 3.0:\n",
    "            apply_compression = True\n",
    "            comp_threshold = -25.0\n",
    "            comp_ratio = 1.5\n",
    "        elif dynamic_range > 18 and duration <= 3.0:\n",
    "            apply_compression = True\n",
    "            comp_threshold = -22.0  # Lower threshold for shorter audio\n",
    "            comp_ratio = 1.2  # Slightly weaker compression\n",
    "        else:\n",
    "            apply_compression = False\n",
    "            comp_threshold = None\n",
    "            comp_ratio = None\n",
    "\n",
    "        # Refined EQ logic for short audio\n",
    "        if mean_energy > 0:\n",
    "            if low_energy > (mean_energy * 1.5):\n",
    "                high_pass_cutoff = 400\n",
    "            else:\n",
    "                high_pass_cutoff = 250\n",
    "\n",
    "            if high_energy > (mean_energy * 1.5):\n",
    "                low_pass_cutoff = 3500\n",
    "            else:\n",
    "                low_pass_cutoff = 4500\n",
    "        else:\n",
    "            high_pass_cutoff = 250\n",
    "            low_pass_cutoff = 4500\n",
    "\n",
    "        # Adjust for short audio (2–3 seconds)\n",
    "        if duration < 3.0:\n",
    "            skip_eq = False  # Apply EQ since audio is valid for full processing\n",
    "            noise_prop_decrease = 0.2  # Moderate noise reduction\n",
    "        else:\n",
    "            skip_eq = False  # Always process EQ for longer audio\n",
    "\n",
    "        # Skip EQ for clean audio with very low noise\n",
    "        if noise_level < -30:\n",
    "            skip_eq = True\n",
    "\n",
    "        print(\"Analysis complete. Parameters chosen:\")\n",
    "        print(f\"Noise Prop Decrease: {noise_prop_decrease}\")\n",
    "        print(f\"Apply Compression: {apply_compression}, Threshold: {comp_threshold}, Ratio: {comp_ratio}\")\n",
    "        print(f\"EQ: Low-pass {low_pass_cutoff} Hz, High-pass {high_pass_cutoff} Hz, Skip EQ: {skip_eq}\")\n",
    "\n",
    "        return {\n",
    "            'noise_prop_decrease': noise_prop_decrease,\n",
    "            'apply_compression': apply_compression,\n",
    "            'comp_threshold': comp_threshold,\n",
    "            'comp_ratio': comp_ratio,\n",
    "            'high_pass_cutoff': high_pass_cutoff,\n",
    "            'low_pass_cutoff': low_pass_cutoff,\n",
    "            'skip_eq': skip_eq\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error in analyzing audio: {e}\")\n",
    "        return {\n",
    "            'noise_prop_decrease': 0.2,\n",
    "            'apply_compression': False,\n",
    "            'comp_threshold': None,\n",
    "            'comp_ratio': None,\n",
    "            'high_pass_cutoff': 200,\n",
    "            'low_pass_cutoff': 3000,\n",
    "            'skip_eq': True\n",
    "        }\n",
    "\n",
    "# Noise level detection\n",
    "def detect_noise_level(input_file):\n",
    "    try:\n",
    "        audio = AudioSegment.from_wav(input_file)\n",
    "        noise_level = audio.dBFS\n",
    "        print(f\"Detected noise level: {noise_level:.2f} dBFS\")\n",
    "        return noise_level\n",
    "    except Exception as e:\n",
    "        print(f\"Error in detecting noise level: {e}\")\n",
    "        return -100\n",
    "\n",
    "# Preprocess audio pipeline\n",
    "def preprocess_audio(input_file, output_file):\n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"Error: File {input_file} does not exist.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Preprocessing {input_file}...\")\n",
    "\n",
    "    try:\n",
    "        # Load audio and check duration\n",
    "        audio = AudioSegment.from_wav(input_file)\n",
    "        audio_duration = len(audio) / 1000.0  # Convert from ms to seconds\n",
    "\n",
    "        if audio_duration < 1.4:\n",
    "            print(\"Audio is too short and may be too fast. Slowing down...\")\n",
    "            temp_slowed_file = \"temp_slowed.wav\"\n",
    "            slow_down_preserving_pitch(input_file, temp_slowed_file, stretch_factor=0.85)\n",
    "            input_file = temp_slowed_file  # Update input file to the slowed version\n",
    "\n",
    "        # Reanalyze audio after slowing down (if applicable)\n",
    "        params = analyze_audio(input_file)\n",
    "\n",
    "        # Perform noise reduction\n",
    "        noise_reduced_file = \"temp_noise_reduced.wav\"\n",
    "        adaptive_noise_reduction(input_file, noise_reduced_file, params['noise_prop_decrease'])\n",
    "\n",
    "        processed_file = noise_reduced_file\n",
    "\n",
    "        # Apply compression if needed\n",
    "        if params['apply_compression']:\n",
    "            compressed_file = \"temp_compressed.wav\"\n",
    "            compress_and_amplify(processed_file, compressed_file, params['comp_threshold'], params['comp_ratio'])\n",
    "            processed_file = compressed_file\n",
    "\n",
    "        # Apply EQ if not skipped\n",
    "        if not params['skip_eq']:\n",
    "            equalized_file = \"temp_equalized.wav\"\n",
    "            apply_equalization(processed_file, equalized_file, params['low_pass_cutoff'], params['high_pass_cutoff'])\n",
    "            processed_file = equalized_file\n",
    "\n",
    "        # Convert to mono, 16kHz, and normalize at the end\n",
    "        print(\"Converting to mono, adjusting sample rate, and normalizing final audio...\")\n",
    "        if not os.path.exists(processed_file):\n",
    "            print(\"Error: Processed file does not exist, aborting.\")\n",
    "            return None\n",
    "\n",
    "        final_audio = AudioSegment.from_wav(processed_file).set_channels(1).set_frame_rate(16000)\n",
    "        final_audio = effects.normalize(final_audio)\n",
    "\n",
    "        final_length = len(final_audio) / 1000.0\n",
    "        print(f\"Final audio duration: {final_length:.2f}s\")\n",
    "\n",
    "        final_audio.export(output_file, format=\"wav\")\n",
    "        print(f\"Final preprocessed audio saved to {output_file}, length: {final_length:.2f}s\")\n",
    "\n",
    "        return output_file\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing audio: {e}\")\n",
    "        return None\n",
    "# Transcribe using Whisper\n",
    "def transcribe_whisper(audio_file, model_type=\"base\"):\n",
    "    print(f\"Processing audio file: {audio_file} with Whisper\")\n",
    "    try:\n",
    "        model = whisper.load_model(model_type)\n",
    "        result = model.transcribe(audio_file)\n",
    "        return result[\"text\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing audio with Whisper: {e}\")\n",
    "        return \"Error: Failed to process audio with Whisper.\"\n",
    "\n",
    "# Calculate WER\n",
    "def calculate_wer_custom(reference, hypothesis):\n",
    "    \"\"\"\n",
    "    Calculates Word Error Rate (WER) with normalization applied.\n",
    "    \"\"\"\n",
    "    reference = normalize_text(reference)\n",
    "    hypothesis = normalize_text(hypothesis)\n",
    "    return jiwer.wer(reference, hypothesis) * 100\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_asr():\n",
    "    audio_files = [\n",
    "        {\"file\": \"Ex4_audio_files/EN/checkin.wav\", \"lang\": \"en\", \"truth\": \"Where is the check-in desk?\"},\n",
    "        {\"file\": \"Ex4_audio_files/EN/parents.wav\", \"lang\": \"en\", \"truth\": \"I have lost my parents.\"},\n",
    "        {\"file\": \"Ex4_audio_files/EN/suitcase.wav\", \"lang\": \"en\", \"truth\": \"Please, I have lost my suitcase.\"},\n",
    "        {\"file\": \"Ex4_audio_files/EN/what_time.wav\", \"lang\": \"en\", \"truth\": \"What time is my plane?\"},\n",
    "        {\"file\": \"Ex4_audio_files/EN/where.wav\", \"lang\": \"en\", \"truth\": \"Where are the restaurants and shops?\"},\n",
    "        {\"file\": \"Ex4_audio_files/IT/checkin_it.wav\", \"lang\": \"it\", \"truth\": \"Dove e' il bancone?\"},\n",
    "        {\"file\": \"Ex4_audio_files/IT/parents_it.wav\", \"lang\": \"it\", \"truth\": \"Ho perso i miei genitori.\"},\n",
    "        {\"file\": \"Ex4_audio_files/IT/suitcase_it.wav\", \"lang\": \"it\", \"truth\": \"Per favore, ho perso la mia valigia.\"},\n",
    "        {\"file\": \"Ex4_audio_files/IT/what_time_it.wav\", \"lang\": \"it\", \"truth\": \"A che ora e' il mio aereo?\"},\n",
    "        {\"file\": \"Ex4_audio_files/IT/where_it.wav\", \"lang\": \"it\", \"truth\": \"Dove sono i ristoranti e i negozi?\"},\n",
    "        {\"file\": \"Ex4_audio_files/ES/checkin_es.wav\", \"lang\": \"es\", \"truth\": \"¿Dónde están los mostradores?\"},\n",
    "        {\"file\": \"Ex4_audio_files/ES/parents_es.wav\", \"lang\": \"es\", \"truth\": \"He perdido a mis padres.\"},\n",
    "        {\"file\": \"Ex4_audio_files/ES/suitcase_es.wav\", \"lang\": \"es\", \"truth\": \"Por favor, he perdido mi maleta.\"},\n",
    "        {\"file\": \"Ex4_audio_files/ES/what_time_es.wav\", \"lang\": \"es\", \"truth\": \"¿A qué hora es mi avión?\"},\n",
    "        {\"file\": \"Ex4_audio_files/ES/where_es.wav\", \"lang\": \"es\", \"truth\": \"¿Dónde están los restaurantes y las tiendas?\"}\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    language_wer = {\"EN\": [], \"IT\": [], \"ES\": []}\n",
    "\n",
    "    for item in audio_files:\n",
    "        file = item[\"file\"]\n",
    "        lang = item[\"lang\"]\n",
    "        truth = item[\"truth\"]\n",
    "\n",
    "        print(f\"\\nProcessing {file} ({lang.upper()})...\")\n",
    "        preprocessed_file = f\"preprocessed_{os.path.basename(file)}\"\n",
    "        recognized_text = \"\"\n",
    "\n",
    "        try:\n",
    "            preprocess_audio(file, preprocessed_file)\n",
    "            recognized_text = transcribe_whisper(preprocessed_file)\n",
    "        except Exception as e:\n",
    "            recognized_text = f\"Error: {e}\"\n",
    "\n",
    "        wer = calculate_wer_custom(truth, recognized_text)\n",
    "        print(f\"Reference: {truth}\")\n",
    "        print(f\"Recognized: {recognized_text}\")\n",
    "        print(f\"WER: {wer}%\")\n",
    "\n",
    "        language_wer[lang.upper()].append(wer)\n",
    "\n",
    "        results.append({\"File\": file, \"Language\": lang.upper(), \"WER\": wer})\n",
    "\n",
    "    print(\"\\n--- Evaluation Results ---\")\n",
    "    for res in results:\n",
    "        print(f\"{res['File']:<30} {res['Language']:<10} {res['WER']:<10}\")\n",
    "\n",
    "    print(\"\\n--- Average WER by Language ---\")\n",
    "    for lang, wer_list in language_wer.items():\n",
    "        avg_wer = sum(wer_list) / len(wer_list) if wer_list else 0\n",
    "        print(f\"{lang}: {avg_wer:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_asr()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
